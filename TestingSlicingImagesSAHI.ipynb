{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0ScZ0lVIXMpgAnDT5Mb0j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1kaiser/test2023/blob/main/TestingSlicingImagesSAHI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rxbAb5VaibGM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee1d0471-86f6-4f59-f60e-d18ad0adeb2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/1kaiser/Snow-cover-area-estimation/releases/download/v1/imagesfolder.zip\n",
            "1116364563/1116364563 [==============================] - 32s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import pathlib\n",
        "dir='/content/files'\n",
        "urls = 'https://github.com/1kaiser/Snow-cover-area-estimation/releases/download/v1/imagesfolder.zip'\n",
        "data_dir = tf.keras.utils.get_file(origin=urls,\n",
        "                                   fname='s',\n",
        "                                   cache_subdir= dir,\n",
        "                                   archive_format='auto',\n",
        "                                   untar=False,\n",
        "                                   extract=True)\n",
        "!rm -r {dir}/s\n",
        "data_dir = pathlib.Path(data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#head"
      ],
      "metadata": {
        "id": "lquyD7ktNdyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os.path\n",
        "import re\n",
        "\n",
        "from osgeo import gdal\n",
        "\n",
        "def tif2array(input_file, calc_gain=True):\n",
        "\n",
        "    dataset = gdal.Open(input_file, gdal.GA_ReadOnly)\n",
        "    image_datatype = dataset.GetRasterBand(1).DataType\n",
        "    image = np.zeros((dataset.RasterYSize, dataset.RasterXSize, dataset.RasterCount), dtype=float)\n",
        "   \n",
        "    # Loop over all bands in dataset\n",
        "    for b in range(dataset.RasterCount):\n",
        "        # Remember, GDAL index is on 1, but Python is on 0 -- so we add 1 for our GDAL calls\n",
        "        band = dataset.GetRasterBand(b + 1)\n",
        "        # Read in the band's data into the third dimension of our array\n",
        "        image[:, :, b] = band.ReadAsArray()\n",
        "    return image, dataset\n"
      ],
      "metadata": {
        "id": "JAarwl2xij8I"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = r'/content/files/'\n",
        "\n",
        "#############################################################################\n",
        "prefix = \"sur_refl_\"\n",
        "end = [\"b01\", \"b02\", \"b03\", \"b04\", \"b05\", \"b06\", \"b07\", \"day_of_year\", \"qc_500m\", \"raz\", \"state_500m\", \"szen\", \"vzen\"]\n",
        "DayOY = \"_doy\\[0-9]+_aid0001\"\n",
        "fileExt = r'.tif'\n",
        "expression_b1 = prefix+end[0]\n",
        "expression_b2 = prefix+end[1]\n",
        "expression_b3 = prefix+end[2]\n",
        "expression_b4 = prefix+end[3]\n",
        "expression_b5 = prefix+end[4]\n",
        "expression_b6 = prefix+end[5]\n",
        "expression_b7 = prefix+end[6]\n",
        "\n",
        "\n",
        "imgs_list_b1 = [f for f in os.listdir(image_dir) if f.__contains__(expression_b1)]\n",
        "\n",
        "imgs_list_b1.sort(reverse=True)       "
      ],
      "metadata": {
        "id": "18V2j8zai4Qj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "temp_dir = r'/content/'\n",
        "\n",
        "def ybatchedimages(images_path, image_list, batch_idx):\n",
        "  images = []\n",
        "  path = os.path.join(images_path, image_list[batch_idx])\n",
        "  pathb2 = path.replace(expression_b1, expression_b2)\n",
        "  pathb4 = path.replace(expression_b1, expression_b4)\n",
        "  pathb6 = path.replace(expression_b1, expression_b6)\n",
        "\n",
        "  #creating file NDSI\n",
        "  !gdal_calc.py \\\n",
        "    --overwrite \\\n",
        "    --type=Float32 \\\n",
        "    --NoDataValue=0 \\\n",
        "    -A {pathb4} \\\n",
        "    --A_band 1 \\\n",
        "    -B {pathb6} \\\n",
        "    --B_band 1 \\\n",
        "    -C {pathb2} \\\n",
        "    --C_band 1 \\\n",
        "    --outfile={temp_dir}\"BothCheck_result_final.tif\" \\\n",
        "    --calc=\"(((A.astype(float) - B)/(A.astype(float) + B))>=0.4)*(C.astype(float)/10000>0.11)\"\n",
        "\n",
        "  pathout = temp_dir+str('BothCheck_result_final.tif')\n",
        "  images.append(tif2array(pathout, 0)[0])\n",
        "\n",
        "  !rm -r {temp_dir}\"BothCheck_result_final.tif\"\n",
        "  output.clear()\n",
        "  return images\n",
        "\n",
        "\n",
        "import jax.numpy as jnp\n",
        "def xbatchedimages(images_path, image_list, batch_idx):\n",
        "  images = []\n",
        "  path = os.path.join(images_path, image_list[batch_idx])\n",
        "  v1 = tif2array(path.replace(expression_b1, expression_b1),0)[0]\n",
        "  v2 = jnp.append(v1, tif2array(path.replace(expression_b1, expression_b2),0)[0] , axis =2)\n",
        "  v3 = jnp.append(v2, tif2array(path.replace(expression_b1, expression_b3),0)[0] , axis =2)\n",
        "  v4 = jnp.append(v3, tif2array(path.replace(expression_b1, expression_b4),0)[0] , axis =2)\n",
        "  v5 = jnp.append(v4, tif2array(path.replace(expression_b1, expression_b5),0)[0] , axis =2)\n",
        "  v6 = jnp.append(v5, tif2array(path.replace(expression_b1, expression_b6),0)[0] , axis =2)\n",
        "  v7 = jnp.append(v6, tif2array(path.replace(expression_b1, expression_b7),0)[0] , axis =2)\n",
        "  images.append(v7)\n",
        "  w1 = tif2array(path.replace(expression_b1, expression_b1),0)[0]\n",
        "  w2 = tif2array(path.replace(expression_b1, expression_b2),0)[0]\n",
        "  w3 = tif2array(path.replace(expression_b1, expression_b3),0)[0]\n",
        "  w4 = tif2array(path.replace(expression_b1, expression_b4),0)[0]\n",
        "  w5 = tif2array(path.replace(expression_b1, expression_b5),0)[0]\n",
        "  w6 = tif2array(path.replace(expression_b1, expression_b6),0)[0]\n",
        "  w7 = tif2array(path.replace(expression_b1, expression_b7),0)[0]\n",
        "  return images\n",
        "\n",
        "import jax.random as random\n",
        "import jax.numpy as jnp\n",
        "batch_size = 1\n",
        "no_of_batches = int(len(imgs_list_b1)/batch_size)\n",
        "def data_stream(i, no_of_batches):\n",
        "  return jnp.asarray(xbatchedimages(image_dir, imgs_list_b1, i)), jnp.asarray(ybatchedimages(image_dir, imgs_list_b1, i))"
      ],
      "metadata": {
        "id": "2OwS8RhHi_QD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "FUxTs7XpkfIv"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_slice_bboxes( image_height: int, image_width: int, slice_height: int = 224 , slice_width: int = 224, overlap_height_ratio: float = 0.0, overlap_width_ratio: float = 0.0 ):\n",
        "  # \"\"\"Slices `image_pil` in crops.\n",
        "  # Corner values of each slice will be generated using the `slice_height`,\n",
        "  # `slice_width`, `overlap_height_ratio` and `overlap_width_ratio` arguments.\n",
        "  # Args:\n",
        "  #     image_height (int): Height of the original image.\n",
        "  #     image_width (int): Width of the original image.\n",
        "  #     slice_height (int): Height of each slice. Default 512.\n",
        "  #     slice_width (int): Width of each slice. Default 512.\n",
        "  #     overlap_height_ratio(float): Fractional overlap in height of each\n",
        "  #         slice (e.g. an overlap of 0.2 for a slice of size 100 yields an\n",
        "  #         overlap of 20 pixels). Default 0.2.\n",
        "  #     overlap_width_ratio(float): Fractional overlap in width of each\n",
        "  #         slice (e.g. an overlap of 0.2 for a slice of size 100 yields an\n",
        "  #         overlap of 20 pixels). Default 0.2.\n",
        "  #     auto_slice_resolution (bool): if not set slice parameters such as slice_height and slice_width,\n",
        "  #         it enables automatically calculate these params from image resolution and orientation.\n",
        "  # Returns:\n",
        "  #     List[List[int]]: List of 4 corner coordinates for each N slices.\n",
        "  #         [\n",
        "  #             [slice_0_left, slice_0_top, slice_0_right, slice_0_bottom],\n",
        "  #             ...\n",
        "  #             [slice_N_left, slice_N_top, slice_N_right, slice_N_bottom]\n",
        "  #         ]\n",
        "  # \"\"\"\n",
        "  slice_bboxes = []\n",
        "  y_max = y_min = 0\n",
        "\n",
        "  if slice_height and slice_width:\n",
        "      y_overlap = int(overlap_height_ratio * slice_height)\n",
        "      x_overlap = int(overlap_width_ratio * slice_width)\n",
        "  else:\n",
        "      raise ValueError(\"Compute type is not auto and slice width and height are not provided.\")\n",
        "\n",
        "  while y_max < image_height:\n",
        "      x_min = x_max = 0\n",
        "      y_max = y_min + slice_height\n",
        "      while x_max < image_width:\n",
        "          x_max = x_min + slice_width\n",
        "          if y_max > image_height or x_max > image_width:\n",
        "              xmax = min(image_width, x_max)\n",
        "              ymax = min(image_height, y_max)\n",
        "              xmin = max(0, xmax - slice_width)\n",
        "              ymin = max(0, ymax - slice_height)\n",
        "              slice_bboxes.append([xmin, ymin, xmax, ymax])\n",
        "          else:\n",
        "              slice_bboxes.append([x_min, y_min, x_max, y_max])\n",
        "          x_min = x_max - x_overlap\n",
        "      y_min = y_max - y_overlap\n",
        "  return slice_bboxes\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "slices = get_slice_bboxes(233, 454)\n",
        "for slice in slices:\n",
        "  print(slice)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVgJexoblT6U",
        "outputId": "fa44bf2d-6f44-48e9-a4c8-18671f07d7df"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 224, 224]\n",
            "[224, 0, 448, 224]\n",
            "[230, 0, 454, 224]\n",
            "[0, 9, 224, 233]\n",
            "[224, 9, 448, 233]\n",
            "[230, 9, 454, 233]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = data_stream(110, no_of_batches)\n",
        "# print(b)\n",
        "\n",
        "def slicedImageInput(i, b):\n",
        "    b1 = b[0]\n",
        "    b1.swapaxes(1,3).swapaxes(2,3)\n",
        "    ######################<< xinput images sliced\n",
        "    ximages = []\n",
        "    for j in range(b1.shape[3]):\n",
        "      if (j==0):\n",
        "        a = b1[:, i[1]:i[3], i[0]:i[2], j]\n",
        "      else:\n",
        "        a = np.append(a, b1[:, i[1]:i[3], i[0]:i[2], j], axis = 0)\n",
        "    ximages = np.expand_dims(a, axis = 0)\n",
        "    ximages = ximages.swapaxes(1,2).swapaxes(2,3)\n",
        "\n",
        "    b2 = b[1]\n",
        "    b2.swapaxes(1,3).swapaxes(2,3)\n",
        "    ######################<< yinput images sliced\n",
        "    yimages = []\n",
        "    for j in range(b2.shape[3]):\n",
        "      if (j==0):\n",
        "        a = b2[:, i[1]:i[3], i[0]:i[2], j]\n",
        "      else:\n",
        "        a = np.append(a, b2[:, i[1]:i[3], i[0]:i[2], j], axis = 0)\n",
        "    yimages = np.expand_dims(a, axis = 0)\n",
        "    yimages = yimages.swapaxes(1,2).swapaxes(2,3)\n",
        "    return ximages, yimages\n",
        "\n",
        "for i in get_slice_bboxes(b[0].shape[1], b[0].shape[2]):\n",
        "  print(i, \"<< th slice\")\n",
        "  slicedImageInput(i, b)\n",
        "\n",
        "# slicedImageInput(get_slice_bboxes(b[0].shape[1], b[0].shape[2])[0], b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj9KT7-HNBXe",
        "outputId": "1532c0ff-7457-46f2-f49d-2d6863f554dd"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 256, 233] << th slice\n",
            "[198, 0, 454, 233] << th slice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_slice_bboxes(b.shape[2], b.shape[3])\n",
        "b[:,4,i[1]:i[3], i[0]:i[2]].shape"
      ],
      "metadata": {
        "id": "wi46MnYgSm_Y",
        "outputId": "6b778f63-9898-4f2e-a076-312b146f2cf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 224, 224)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def slice_image(\n",
        "    image: Union[str, Image.Image],\n",
        "    output_file_name: Optional[str] = None,\n",
        "    output_dir: Optional[str] = None,\n",
        "    out_ext: Optional[str] = None,\n",
        "    verbose: bool = False,\n",
        ") -> SliceImageResult:\n",
        "    \"\"\"Slice a large image into smaller windows. If output_file_name is given export\n",
        "    sliced images.\n",
        "    Args:\n",
        "        image (str or PIL.Image): File path of image or Pillow Image to be sliced.\n",
        "        coco_annotation_list (CocoAnnotation): List of CocoAnnotation objects.\n",
        "        output_file_name (str, optional): Root name of output files (coordinates will\n",
        "            be appended to this)\n",
        "        output_dir (str, optional): Output directory\n",
        "        slice_height (int): Height of each slice. Default 512.\n",
        "        slice_width (int): Width of each slice. Default 512.\n",
        "        overlap_height_ratio (float): Fractional overlap in height of each\n",
        "            slice (e.g. an overlap of 0.2 for a slice of size 100 yields an\n",
        "            overlap of 20 pixels). Default 0.2.\n",
        "        overlap_width_ratio (float): Fractional overlap in width of each\n",
        "            slice (e.g. an overlap of 0.2 for a slice of size 100 yields an\n",
        "            overlap of 20 pixels). Default 0.2.\n",
        "        auto_slice_resolution (bool): if not set slice parameters such as slice_height and slice_width,\n",
        "            it enables automatically calculate these params from image resolution and orientation.\n",
        "        min_area_ratio (float): If the cropped annotation area to original annotation\n",
        "            ratio is smaller than this value, the annotation is filtered out. Default 0.1.\n",
        "        out_ext (str, optional): Extension of saved images. Default is the\n",
        "            original suffix.\n",
        "        verbose (bool, optional): Switch to print relevant values to screen.\n",
        "            Default 'False'.\n",
        "    Returns:\n",
        "        sliced_image_result: SliceImageResult:\n",
        "                                sliced_image_list: list of SlicedImage\n",
        "                                image_dir: str\n",
        "                                    Directory of the sliced image exports.\n",
        "                                original_image_size: list of int\n",
        "                                    Size of the unsliced original image in [height, width]\n",
        "        num_total_invalid_segmentation: int\n",
        "            Number of invalid segmentation annotations.\n",
        "    \"\"\"\n",
        "\n",
        "    # define verboseprint\n",
        "    verboselog = logger.info if verbose else lambda *a, **k: None\n",
        "\n",
        "    def _export_single_slice(image: np.ndarray, output_dir: str, slice_file_name: str):\n",
        "        image_pil = read_image_as_pil(image)\n",
        "        slice_file_path = str(Path(output_dir) / slice_file_name)\n",
        "        # export sliced image\n",
        "        image_pil.save(slice_file_path)\n",
        "        image_pil.close()  # to fix https://github.com/obss/sahi/issues/565\n",
        "        verboselog(\"sliced image path: \" + slice_file_path)\n",
        "\n",
        "    # create outdir if not present\n",
        "    if output_dir is not None:\n",
        "        Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # read image\n",
        "    image_pil = read_image_as_pil(image)\n",
        "    verboselog(\"image.shape: \" + str(image_pil.size))\n",
        "\n",
        "    image_width, image_height = image_pil.size\n",
        "    if not (image_width != 0 and image_height != 0):\n",
        "        raise RuntimeError(f\"invalid image size: {image_pil.size} for 'slice_image'.\")\n",
        "    slice_bboxes = get_slice_bboxes(\n",
        "        image_height=image_height,\n",
        "        image_width=image_width,\n",
        "    )\n",
        "\n",
        "    t0 = time.time()\n",
        "    n_ims = 0\n",
        "\n",
        "    # init images and annotations lists\n",
        "    sliced_image_result = SliceImageResult(original_image_size=[image_height, image_width], image_dir=output_dir)\n",
        "\n",
        "    image_pil_arr = np.asarray(image_pil)\n",
        "    # iterate over slices\n",
        "    for slice_bbox in slice_bboxes:\n",
        "        n_ims += 1\n",
        "\n",
        "        # extract image\n",
        "        tlx = slice_bbox[0]\n",
        "        tly = slice_bbox[1]\n",
        "        brx = slice_bbox[2]\n",
        "        bry = slice_bbox[3]\n",
        "        image_pil_slice = image_pil_arr[tly:bry, tlx:brx]\n",
        "\n",
        "        # set image file suffixes\n",
        "        slice_suffixes = \"_\".join(map(str, slice_bbox))\n",
        "        if out_ext:\n",
        "            suffix = out_ext\n",
        "        else:\n",
        "            try:\n",
        "                suffix = Path(image_pil.filename).suffix\n",
        "            except AttributeError:\n",
        "                suffix = \".jpg\"\n",
        "\n",
        "        # set image file name and path\n",
        "        slice_file_name = f\"{output_file_name}_{slice_suffixes}{suffix}\"\n",
        "\n",
        "        # create coco image\n",
        "        slice_width = slice_bbox[2] - slice_bbox[0]\n",
        "        slice_height = slice_bbox[3] - slice_bbox[1]\n",
        "\n",
        "        # create sliced image and append to sliced_image_result\n",
        "        sliced_image = SlicedImage( image=image_pil_slice, starting_pixel=[slice_bbox[0], slice_bbox[1]] )\n",
        "        sliced_image_result.add_sliced_image(sliced_image)\n",
        "\n",
        "    # export slices if output directory is provided\n",
        "    if output_file_name and output_dir:\n",
        "        conc_exec = concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS)\n",
        "        conc_exec.map(\n",
        "            _export_single_slice,\n",
        "            sliced_image_result.images,\n",
        "            [output_dir] * len(sliced_image_result),\n",
        "            sliced_image_result.filenames,\n",
        "        )\n",
        "\n",
        "    verboselog(\n",
        "        \"Num slices: \" + str(n_ims) + \" slice_height: \" + str(slice_height) + \" slice_width: \" + str(slice_width)\n",
        "    )\n",
        "\n",
        "    return sliced_image_result\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bwiE1_ftlWOA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}