{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1kaiser/test2023/blob/main/GoogleEarthEngine_AnySatellite_Data_Download.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy4HceOol_h1",
        "outputId": "9e36dbb6-a2da-4810-9087-aa9b77fa37f8"
      },
      "source": [
        "# Install the library\n",
        "!pip -q install FireHR==0.1.2 pyhdf==0.10.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/149.1 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m143.4/149.1 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.1/149.1 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.3/193.3 KB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.8/776.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.0/56.0 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 KB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.0/79.0 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.7/51.7 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 KB\u001b[0m \u001b[31m405.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 KB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.9/274.9 KB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.6/133.6 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 KB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 KB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 KB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.1/439.1 KB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.0/424.0 KB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 KB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.2/365.2 KB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.2/86.2 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 KB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: jsonschema 4.3.3 does not provide the extra 'format-nongpl'\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for pyhdf (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for cdsapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.7.1 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.7.1 which is incompatible.\n",
            "google-colab 1.0.0 requires notebook~=5.7.16, but you have notebook 6.5.2 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado~=6.0.4, but you have tornado 6.2 which is incompatible.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.0.3 which is incompatible.\n",
            "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 2.3.9 which is incompatible.\n",
            "confection 0.0.3 requires srsly<3.0.0,>=2.4.0, but you have srsly 1.0.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKyI9oFmmvpd",
        "outputId": "b4c93543-85ec-44a5-9b75-6496c35e9439",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Authenticate to use Google Earth Engine API\n",
        "import ee\n",
        "ee.Authenticate()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=TiNpESVRWx6OXNkgzHUOK_JiYbPiLkwUDyEI8U2EZaM&tc=YnLPXfq1-bRghb8X-RbnT9Oyv38OL4tSYaUt1oNd3Mc&cc=qnYpHVE6ZZRFRH3VNh4glXCWTqo-uckC97c-sHfdL6k\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below.\n",
            "Enter verification code: 4/1AWtgzh5Rk3XmWu93-UQvoFEFYlVLAakJHNW9xwNyN3L-YMwIBWqdzV7fmCQ\n",
            "\n",
            "Successfully saved authorization token.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/data"
      ],
      "metadata": {
        "id": "VkDzjn8au_6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**COPERNICUS/S2**"
      ],
      "metadata": {
        "id": "qaYr__CZrM7E"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-rR0f-GmELJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "38bce199-1049-4a04-d9ab-3bbd481284e2"
      },
      "source": [
        "from pathlib import Path\n",
        "from FireHR.data import *\n",
        "\n",
        "# Bounding box coordinates\n",
        "left   = 75.979728\n",
        "right  = 77.866667\n",
        "bottom = 31.453599\n",
        "top    = 32.416667\n",
        "\n",
        "path_save   = Path('data')\n",
        "products    = [\"COPERNICUS/S2\"]  # Product id in google earth engine\n",
        "bands       = ['B4', 'B3', 'B2'] # Red, Green, Blue\n",
        "\n",
        "R = RegionST(name         = 'TeslaGigaBerlin', \n",
        "             bbox         = [left,bottom,right,top], \n",
        "             scale_meters = 10, \n",
        "             time_start   = '2021-03-01', \n",
        "             time_end     = '2021-04-25')\n",
        "\n",
        "# Download time series\n",
        "# download_data_ts(R, products, bands, path_save)\n",
        "\n",
        "time_window = R.times[0], R.times[-1]\n",
        "\n",
        "# Download median composite of the 3 least cloudy images within the time_window\n",
        "download_data(R, time_window, products, bands, path_save, use_least_cloudy=3, show_progress=True)\n",
        "\n",
        "#download_data_ts(R, products, bands, path_save, show_progress=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='231' class='' max='231' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [231/231 16:23&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBTGABv5sm0d"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from banet.data import open_tif\n",
        "\n",
        "brightness = 3\n",
        "im = np.concatenate([open_tif(f'data/download.{b}.tif').read() for b in bands])\n",
        "im = im.transpose(1,2,0).astype(np.float32)/10000\n",
        "plt.imshow(brightness*im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**GEDI**"
      ],
      "metadata": {
        "id": "Namgq3XVrIgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from FireHR.data import *\n",
        "\n",
        "# Bounding box coordinates\n",
        "left   = 75.979728\n",
        "right  = 77.866667\n",
        "bottom = 31.453599\n",
        "top    = 32.416667\n",
        "\n",
        "path_save   = Path('data')\n",
        "products    = [\"LARSE/GEDI/GEDI02_A_002_MONTHLY\"]  # Product id in google earth engine\n",
        "bands       = ['rh98', 'rh38', 'rh10'] # Red, Green, Blue\n",
        "\n",
        "R = RegionST(name         = 'TeslaGigaBerlin', \n",
        "             bbox         = [left,bottom,right,top], \n",
        "             scale_meters = 10, \n",
        "             time_start   = '2020-03-01', \n",
        "             time_end     = '2020-04-25')\n",
        "\n",
        "# Download time series\n",
        "# download_data_ts(R, products, bands, path_save)\n",
        "\n",
        "time_window = R.times[0], R.times[-1]\n",
        "\n",
        "# Download median composite of the 3 least cloudy images within the time_window\n",
        "download_data(R, time_window, products, bands, path_save, use_least_cloudy=3, show_progress=True)\n",
        "\n",
        "#download_data_ts(R, products, bands, path_save, show_progress=True)"
      ],
      "metadata": {
        "id": "KOre-TKTrGsW",
        "outputId": "5559031c-4ba7-4fbe-a854-b907d182ee32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='231' class='' max='231' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [231/231 15:27&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/FireHR/data.py:136: UserWarning: Total number of images in the collection 2 less than n=3. Setting n=2\n",
            "  warnings.warn(f'Total number of images in the collection {colsize} less than n={n}. Setting n={colsize}')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**EO1/HYPERION**"
      ],
      "metadata": {
        "id": "EP8-jdvMdPk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from FireHR.data import *\n",
        "\n",
        "# Bounding box coordinates\n",
        "left   = 75.979728\n",
        "right  = 77.866667\n",
        "bottom = 31.453599\n",
        "top    = 32.416667\n",
        "\n",
        "path_save   = Path('data')\n",
        "products    = [\"EO1/HYPERION\"]  # Product id in google earth engine\n",
        "bands       = ['B104', 'B140', 'B221'] # Red, Green, Blue\n",
        "\n",
        "R = RegionST(name         = 'TeslaGigaBerlin', \n",
        "             bbox         = [left,bottom,right,top], \n",
        "             scale_meters = 10, \n",
        "             time_start   = '2015-03-01', \n",
        "             time_end     = '2016-07-25')\n",
        "\n",
        "# Download time series\n",
        "# download_data_ts(R, products, bands, path_save)\n",
        "\n",
        "time_window = R.times[0], R.times[-1]\n",
        "\n",
        "# Download median composite of the 3 least cloudy images within the time_window\n",
        "download_data(R, time_window, products, bands, path_save, use_least_cloudy=3, show_progress=True)\n",
        "\n",
        "#download_data_ts(R, products, bands, path_save, show_progress=True)"
      ],
      "metadata": {
        "id": "-dgTB5aNdVMV",
        "outputId": "fd615cb4-edf9-4122-82fe-8d87e28feb8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='0' class='' max='231' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/231 00:00&lt;?]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "EEException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ee/data.py\u001b[0m in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    325\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHttpError\u001b[0m: <HttpError 400 when requesting https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/value:compute?prettyPrint=false&alt=json returned \"Collection.toList: The value of 'count' must be positive. Got: 0.\". Details: \"Collection.toList: The value of 'count' must be positive. Got: 0.\">",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mEEException\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a6d0d6b705fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Download median composite of the 3 least cloudy images within the time_window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mdownload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproducts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_least_cloudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#download_data_ts(R, products, bands, path_save, show_progress=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/FireHR/data.py\u001b[0m in \u001b[0;36mdownload_data\u001b[0;34m(R, times, products, bands, path_save, scale, max_cloud_fraction, use_least_cloudy, download_crop_size, show_progress)\u001b[0m\n\u001b[1;32m    192\u001b[0m                     \u001b[0mimCol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_cloudy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimCol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_cloud_fraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_cloud_fraction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_least_cloudy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m                     \u001b[0mimCol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_least_cloudy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimCol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_least_cloudy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m                 \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimCol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mimCol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageCollection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/FireHR/data.py\u001b[0m in \u001b[0;36mn_least_cloudy\u001b[0;34m(image_collection, n)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mimage_collection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'CLOUDY_PIXEL_PERCENTAGE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mimage_collection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mcolsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolsize\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Total number of images in the collection {colsize} less than n={n}. Setting n={colsize}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ee/computedobject.py\u001b[0m in \u001b[0;36mgetInfo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[0mto\u001b[0m \u001b[0manything\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \"\"\"\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputeValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ee/data.py\u001b[0m in \u001b[0;36mcomputeValue\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    774\u001b[0m   \u001b[0m_maybe_populate_workload_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m   return _execute_cloud_call(\n\u001b[0m\u001b[1;32m    777\u001b[0m       _get_cloud_api_resource().projects().value().compute(\n\u001b[1;32m    778\u001b[0m           \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ee/data.py\u001b[0m in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0m_translate_cloud_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEEException\u001b[0m: Collection.toList: The value of 'count' must be positive. Got: 0."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**JAXA/ALOS/PALSAR-2/Level2_2/ScanSAR**"
      ],
      "metadata": {
        "id": "C1hnMrqQklVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from FireHR.data import *\n",
        "\n",
        "# Bounding box coordinates\n",
        "left   = 75.979728\n",
        "right  = 77.866667\n",
        "bottom = 31.453599\n",
        "top    = 32.416667\n",
        "\n",
        "path_save   = Path('data')\n",
        "products    = [\"JAXA/ALOS/PALSAR-2/Level2_2/ScanSAR\"]  # Product id in google earth engine\n",
        "bands       = ['HH', 'HV'] # Red, Green, Blue\n",
        "\n",
        "R = RegionST(name         = 'TeslaGigaBerlin', \n",
        "             bbox         = [left,bottom,right,top], \n",
        "             scale_meters = 10, \n",
        "             time_start   = '2020-03-01', \n",
        "             time_end     = '2020-04-25')\n",
        "\n",
        "# Download time series\n",
        "# download_data_ts(R, products, bands, path_save)\n",
        "\n",
        "time_window = R.times[0], R.times[-1]\n",
        "\n",
        "# Download median composite of the 3 least cloudy images within the time_window\n",
        "download_data(R, time_window, products, bands, path_save, use_least_cloudy=3, show_progress=True)\n",
        "\n",
        "#download_data_ts(R, products, bands, path_save, show_progress=True)"
      ],
      "metadata": {
        "id": "ZTOhM6KakmxT",
        "outputId": "74c373a7-af35-49aa-b733-8613f60820ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='231' class='' max='231' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [231/231 47:29&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**bare code**"
      ],
      "metadata": {
        "id": "_bmbtllFy7KQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#export\n",
        "import ee\n",
        "import os\n",
        "import requests\n",
        "import rasterio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import json\n",
        "from IPython.core.debugger import set_trace\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "from fastprogress.fastprogress import progress_bar\n",
        "from banet.geo import open_tif, merge, Region\n",
        "from banet.geo import downsample\n",
        "     \n",
        "\n",
        "#export\n",
        "class RegionST(Region):\n",
        "    \"Defines a region in space and time with a name, a bounding box and the pixel size.\"\n",
        "    def __init__(self, name:str, bbox:list, pixel_size:float=None, scale_meters:int=None,\n",
        "                 time_start:str=None, time_end:str=None, time_freq:str='D', time_margin:int=0,\n",
        "                 shape:tuple=None, epsg=4326):\n",
        "        if scale_meters is not None and pixel_size is not None: \n",
        "            raise Exception('Either pixel_size or scale_meters must be set to None.')\n",
        "        self.name = name\n",
        "        self.bbox = rasterio.coords.BoundingBox(*bbox) # left, bottom, right, top\n",
        "        if pixel_size is not None:\n",
        "            self.pixel_size = pixel_size\n",
        "        else:\n",
        "            self.pixel_size = scale_meters/111000\n",
        "        self.epsg         = epsg\n",
        "        self.scale_meters = scale_meters\n",
        "        self._shape       = shape\n",
        "        self.time_start   = pd.Timestamp(str(time_start))\n",
        "        self.time_end     = pd.Timestamp(str(time_end))\n",
        "        self.time_margin  = time_margin\n",
        "        self.time_freq    = time_freq\n",
        "\n",
        "    @property\n",
        "    def shape(self):\n",
        "        \"Shape of the region (height, width)\"\n",
        "        if self._shape is None:\n",
        "            return (self.height, self.width)\n",
        "        else: return self._shape\n",
        "        \n",
        "    @property\n",
        "    def times(self):\n",
        "        \"Property that computes the date_range for the region.\"\n",
        "        tstart = self.time_start - pd.Timedelta(days=self.time_margin)\n",
        "        tend = self.time_end + pd.Timedelta(days=self.time_margin)\n",
        "        return pd.date_range(tstart, tend, freq=self.time_freq)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file, time_start=None, time_end=None):\n",
        "        \"Loads region information from json file\"\n",
        "        with open(file, 'r') as f:\n",
        "            args = json.load(f)\n",
        "        if time_start is None:\n",
        "            time_start = args['time_start']\n",
        "        if time_end is None:\n",
        "            time_end = args['time_end']\n",
        "        return cls(args['name'], args['bbox'], args['pixel_size'],\n",
        "                   time_start=time_start, time_end=time_end)\n",
        "    \n",
        "def extract_region(df_row, cls=Region):\n",
        "    \"Create Region object from a row of the metadata dataframe.\"\n",
        "    if issubclass(cls, RegionST):\n",
        "        return cls(df_row.event_id, df_row.bbox, df_row.pixel_size, \n",
        "                   df_row.time_start, df_row.time_end)\n",
        "    elif issubclass(cls, Region):\n",
        "        return cls(df_row.event_id, df_row.bbox, df_row.pixel_size)\n",
        "    else: raise NotImplemented('cls must be one of the following [Region, RegionST]')\n",
        "     \n",
        "\n",
        "#export\n",
        "def coords2bbox(lon, lat, pixel_size): \n",
        "    return [lon.min(), lat.min(), lon.max()+pixel_size, lat.max()+pixel_size]\n",
        "\n",
        "def split_region(region:RegionST, size:int, cls=Region):\n",
        "    lon, lat = region.coords()\n",
        "    Nlon = (len(lon)//size)*size\n",
        "    Nlat = (len(lat)//size)*size\n",
        "    lons = [*lon[:Nlon].reshape(-1, size), lon[Nlon:][None]]\n",
        "    lats = [*lat[:Nlat].reshape(-1, size), lat[Nlat:][None]]\n",
        "    if len(lats[-1].reshape(-1)) == 0 and len(lons[-1].reshape(-1)) == 0:\n",
        "        lons = lons[:-1]\n",
        "        lats = lats[:-1]\n",
        "    #lons = lon.reshape(-1, size)\n",
        "    #lats = lat.reshape(-1, size)\n",
        "    if issubclass(cls, RegionST):\n",
        "        return [cls('', coords2bbox(ilon, ilat, region.pixel_size), \n",
        "                    pixel_size=region.pixel_size, time_start=region.time_start,\n",
        "                    time_end=region.time_end, time_freq=region.time_freq,\n",
        "                    time_margin=region.time_margin) for ilon in lons for ilat in lats]\n",
        "    elif issubclass(cls, Region):\n",
        "        return [cls('', coords2bbox(ilon, ilat, region.pixel_size), pixel_size=region.pixel_size) \n",
        "            for ilon in lons for ilat in lats]\n",
        "    else: raise NotImplemented('cls must be one of the following [Region, RegionST]')\n",
        "        \n",
        "    return \n",
        "            \n",
        "def merge_tifs(files:list, fname:str, delete=False):\n",
        "    data, tfm = merge([open_tif(str(f)) for f in files])\n",
        "    data = data.squeeze()\n",
        "    fname = Path(files[0]).parent/fname\n",
        "    profile = open_tif(str(files[0])).profile\n",
        "    with rasterio.Env():\n",
        "        height, width = data.shape\n",
        "        profile.update(width=width, height=height, transform=tfm, compress='lzw')\n",
        "        with rasterio.open(str(fname), 'w', **profile) as dst:\n",
        "            dst.write(data, 1)\n",
        "    if delete:\n",
        "        for f in files: os.remove(f)\n",
        "     \n",
        "\n",
        "#export\n",
        "def filter_region(image_collection:ee.ImageCollection, region:RegionST, times:tuple, bands=None):\n",
        "    image_collection = image_collection.filterDate(times[0], times[1])\n",
        "    geometry = ee.Geometry.Rectangle(region.bbox)\n",
        "    image_collection = image_collection.filterBounds(geometry)\n",
        "    if bands is not None:\n",
        "        image_collection = image_collection.select(bands)\n",
        "    return image_collection\n",
        "\n",
        "def filter_cloudy(image_collection:ee.ImageCollection, max_cloud_fraction=0.2):\n",
        "    return image_collection.filterMetadata(\n",
        "        'CLOUDY_PIXEL_PERCENTAGE', 'not_greater_than', max_cloud_fraction)\n",
        "\n",
        "def n_least_cloudy(image_collection:ee.ImageCollection, n=5):\n",
        "    image_collection = image_collection.sort(prop='CLOUDY_PIXEL_PERCENTAGE')\n",
        "    image_collection = image_collection.toList(image_collection.size())\n",
        "    colsize = image_collection.size().getInfo()\n",
        "    if colsize < n: \n",
        "        warnings.warn(f'Total number of images in the collection {colsize} less than n={n}. Setting n={colsize}')\n",
        "        n = colsize\n",
        "    image_collection = ee.ImageCollection([ee.Image(image_collection.get(i)) for i in range(n)])\n",
        "    return image_collection\n",
        "\n",
        "def download_topography_data(R:RegionST, path_save=Path('.'), scale=None, \n",
        "                             download_crop_size=1000, show_progress=False):\n",
        "    if scale is None: scale = R.scale_meters\n",
        "    ee.Initialize()\n",
        "    image = ee.Image('srtm90_v4')\n",
        "    path_save.mkdir(exist_ok=True, parents=True)\n",
        "    sR = [R] if min(R.shape) <= download_crop_size else split_region(R, size=download_crop_size)\n",
        "    if not (path_save/'srtm90_v4.elevation.tif').is_file():\n",
        "        files = []\n",
        "        loop = enumerate(sR) if not show_progress else progress_bar(enumerate(sR),total=len(sR))\n",
        "        for j, R in loop:\n",
        "            region = (f\"[[{R.bbox.left}, {R.bbox.bottom}], [{R.bbox.right}, {R.bbox.bottom}], \" +\n",
        "              f\"[{R.bbox.right}, {R.bbox.top}], [{R.bbox.left}, {R.bbox.top}]]\")\n",
        "            url = image.getDownloadUrl(\n",
        "                {'scale': scale, 'crs': 'EPSG:4326', 'region': f'{region}'})\n",
        "            r = requests.get(url)\n",
        "            with open(str(path_save/'data.zip'), 'wb') as f:\n",
        "                f.write(r.content)\n",
        "            with zipfile.ZipFile(str(path_save/'data.zip'), 'r') as f:\n",
        "                f.extractall(str(path_save))\n",
        "                os.rename(str(path_save/'srtm90_v4.elevation.tif'),\n",
        "                          str(path_save/f'srtm90_v4.elevation_{j}.tif'))\n",
        "                files.append(str(path_save/f'srtm90_v4.elevation_{j}.tif'))\n",
        "            os.remove(str(path_save/'data.zip'))\n",
        "        merge_tifs(files, 'srtm90_v4.elevation.tif', delete=True)\n",
        "\n",
        "def download_data(R:RegionST, times, products, bands, path_save, scale=None, max_cloud_fraction=None,\n",
        "                  use_least_cloudy=None, download_crop_size=1000, show_progress=False):\n",
        "    if scale is None: scale = R.scale_meters\n",
        "    ee.Initialize()\n",
        "    path_save.mkdir(exist_ok=True, parents=True)\n",
        "    if not ((path_save/f'download.{bands[0]}.tif').is_file() and \n",
        "           (path_save/f'download.{bands[1]}.tif').is_file() and\n",
        "           (path_save/f'download.{bands[2]}.tif').is_file()):\n",
        "        sR = [R] if min(R.shape) <= download_crop_size else split_region(R, size=download_crop_size, cls=RegionST)\n",
        "        fsaves = []\n",
        "        #for j, R in tqdm(enumerate(sR), total=len(sR)):\n",
        "        loop = enumerate(sR) if not show_progress else progress_bar(enumerate(sR),total=len(sR))\n",
        "        for j, R in loop:\n",
        "            region = (f\"[[{R.bbox.left}, {R.bbox.bottom}], [{R.bbox.right}, {R.bbox.bottom}], \" +\n",
        "                       f\"[{R.bbox.right}, {R.bbox.top}], [{R.bbox.left}, {R.bbox.top}]]\")\n",
        "\n",
        "            if not ((path_save/f'download.{bands[0]}_{j}.tif').is_file() and \n",
        "                   (path_save/f'download.{bands[1]}_{j}.tif').is_file() and\n",
        "                   (path_save/f'download.{bands[2]}_{j}.tif').is_file()):\n",
        "                # Merge products to single image collection\n",
        "                imCol = ee.ImageCollection(products[0])\n",
        "                for i in range(1, len(products)):\n",
        "                    imCol = imCol.merge(ee.ImageCollection(products[i]))\n",
        "                imCol = filter_region(imCol, R, times=times, bands=bands)\n",
        "                if max_cloud_fraction is not None:\n",
        "                    imCol = filter_cloudy(imCol, max_cloud_fraction=max_cloud_fraction)\n",
        "                if use_least_cloudy is not None:\n",
        "                    imCol = n_least_cloudy(imCol, n=use_least_cloudy)\n",
        "                im = imCol.median()\n",
        "                imCol = ee.ImageCollection([im])\n",
        "                colList = imCol.toList(imCol.size())\n",
        "                # info = colList.getInfo()\n",
        "                # data_times = [pd.to_datetime(o['properties']['system:time_start'], unit='ms') for o in info]\n",
        "                # data_cloudy = [o['properties']['CLOUDY_PIXEL_PERCENTAGE'] for o in info]\n",
        "                # Download each image\n",
        "                for i in range(colList.size().getInfo()):\n",
        "                    image = ee.Image(colList.get(i))\n",
        "                    fname = 'download'\n",
        "                    #fname = image.get('system:id').getInfo().split('/')[-1]\n",
        "                    fnames_full = [f'{fname}.{b}.tif' for b in bands]\n",
        "                    fnames_partial0 = [f'{fname}.{b}_{j}.tif' for b in bands]\n",
        "                    fnames_full = all([(path_save/f).is_file() for f in fnames_full])\n",
        "                    fnames_partial = all([(path_save/f).is_file() for f in fnames_partial0])\n",
        "                    if not fnames_full:\n",
        "                        fsaves.append([path_save/f for f in fnames_partial0])\n",
        "                        if not fnames_partial:\n",
        "                            zip_error = True\n",
        "                            for i in range(10): # Try 10 times\n",
        "                                if zip_error:\n",
        "                                    try:\n",
        "                                        url = image.getDownloadURL(\n",
        "                                            {'scale': scale, 'crs': 'EPSG:4326', \n",
        "                                             'region': f'{region}'})\n",
        "                                        r = requests.get(url)\n",
        "                                        with open(str(path_save/'data.zip'), 'wb') as f:\n",
        "                                            f.write(r.content)\n",
        "                                        with zipfile.ZipFile(str(path_save/'data.zip'), 'r') as f:\n",
        "                                            files = f.namelist()\n",
        "                                            f.extractall(str(path_save))\n",
        "                                        os.remove(str(path_save/'data.zip'))\n",
        "                                        zip_error = False\n",
        "                                    except:\n",
        "                                        zip_error = True\n",
        "                                        os.remove(str(path_save/'data.zip'))\n",
        "                                        time.sleep(10)\n",
        "                            if zip_error: raise Exception(f'Failed to process {url}')\n",
        "                            for f in files:\n",
        "                                f = path_save/f\n",
        "                                os.rename(str(f), str(path_save/f'{f.stem}_{j}{f.suffix}'))\n",
        "        # Merge files\n",
        "        suffix = '.tif'\n",
        "        files = path_save.ls(include=[suffix])\n",
        "        #files = np.unique(fsaves) \n",
        "        files = [o.stem for o in files]\n",
        "        ref = np.unique(['_'.join(o.split('_')[:-1]) \n",
        "                         for o in files if len(o.split('_')[-1]) < 6])\n",
        "        ids = np.unique([int(o.split('_')[-1]) \n",
        "                         for o in files if len(o.split('_')[-1]) < 6])\n",
        "        #file_groups = [[path_save/f'{r}_{i}{suffix}' for i in ids] for r in ref] \n",
        "        file_groups = [[path_save/f'{r}_{i}{suffix}' for i in ids \n",
        "                    if f'{r}_{i}' in files] for r in ref] \n",
        "        for fs in file_groups:\n",
        "            if len(fs) < 500:\n",
        "                fsave = '_'.join(fs[0].stem.split('_')[:-1]) + suffix\n",
        "                merge_tifs(fs, fsave, delete=True)\n",
        "            else:\n",
        "                fs_break = np.array(fs)[:(len(fs)//500)*500].reshape(len(fs)//500,-1).tolist()\n",
        "                if len(fs[(len(fs)//500)*500:]) > 0:\n",
        "                    fs_break.append(fs[(len(fs)//500)*500:])\n",
        "                for fsi, fs2 in enumerate(fs_break):\n",
        "                    fsave = '_'.join(fs2[0].stem.split('_')[:-1]) + f'_break{fsi}' + suffix\n",
        "                    merge_tifs(fs2, fsave, delete=True)\n",
        "\n",
        "        files = path_save.ls(include=[suffix, '_break'])\n",
        "        files = [o.stem for o in files]\n",
        "        ref = np.unique(['_'.join(o.split('_')[:-1]) \n",
        "                         for o in files if len(o.split('_')[-1]) < 11])\n",
        "        ids = np.unique([o.split('_')[-1]\n",
        "                         for o in files if len(o.split('_')[-1]) < 11])\n",
        "        #file_groups = [[path_save/f'{r}_{i}{suffix}' for i in ids] for r in ref] \n",
        "        file_groups = [[path_save/f'{r}_{i}{suffix}' for i in ids \n",
        "                    if f'{r}_{i}' in files] for r in ref] \n",
        "        for fs in file_groups:\n",
        "            fsave = '_'.join(fs[0].stem.split('_')[:-1]) + suffix\n",
        "            merge_tifs(fs, fsave, delete=True)\n",
        "            \n",
        "def download_data_ts(R:RegionST, products, bands, path_save, scale=None, \n",
        "                     download_crop_size=1000, show_progress=False):\n",
        "    if scale is None: scale = R.scale_meters\n",
        "    ee.Initialize()\n",
        "    times = (R.times[0], R.times[-1])\n",
        "    path_save.mkdir(exist_ok=True, parents=True)\n",
        "    sR = [R] if min(R.shape) <= download_crop_size else split_region(R, size=download_crop_size, cls=RegionST)\n",
        "    loop = enumerate(sR) if not show_progress else progress_bar(enumerate(sR),total=len(sR))\n",
        "    for j, R in loop:\n",
        "        region = (f\"[[{R.bbox.left}, {R.bbox.bottom}], [{R.bbox.right}, {R.bbox.bottom}], \" +\n",
        "                   f\"[{R.bbox.right}, {R.bbox.top}], [{R.bbox.left}, {R.bbox.top}]]\")\n",
        "\n",
        "        # Merge products to single image collection\n",
        "        imCol = ee.ImageCollection(products[0])\n",
        "        for i in range(1, len(products)):\n",
        "            imCol = imCol.merge(ee.ImageCollection(products[i]))\n",
        "        imCol = filter_region(imCol, R, times=times, bands=bands)\n",
        "        imCol = ee.ImageCollection(imCol)\n",
        "        colList = imCol.toList(imCol.size())\n",
        "\n",
        "        # Download each image\n",
        "        for i in range(colList.size().getInfo()):\n",
        "            image = ee.Image(colList.get(i))\n",
        "            zip_error = True\n",
        "            for i in range(10): # Try 10 times\n",
        "                if zip_error:\n",
        "                    try:\n",
        "                        url = image.getDownloadURL(\n",
        "                            {'scale': scale, 'crs': 'EPSG:4326', \n",
        "                             'region': f'{region}'})\n",
        "                        r = requests.get(url)\n",
        "                        with open(str(path_save/'data.zip'), 'wb') as f:\n",
        "                            f.write(r.content)\n",
        "                        with zipfile.ZipFile(str(path_save/'data.zip'), 'r') as f:\n",
        "                            files = f.namelist()\n",
        "                            f.extractall(str(path_save))\n",
        "                        os.remove(str(path_save/'data.zip'))\n",
        "                        zip_error = False\n",
        "                    except:\n",
        "                        zip_error = True\n",
        "                        os.remove(str(path_save/'data.zip'))\n",
        "                        time.sleep(10)\n",
        "            if zip_error: raise Exception(f'Failed to process {url}')\n",
        "            for f in files:\n",
        "                f = path_save/f\n",
        "                os.rename(str(f), str(path_save/f'{f.stem}_{j}{f.suffix}'))\n",
        "                \n",
        "    # Merge files\n",
        "    suffix = '.tif'\n",
        "    files = path_save.ls(include=[suffix])\n",
        "    files = [o.stem for o in files]\n",
        "    ref = np.unique(['_'.join(o.split('_')[:-1]) \n",
        "                     for o in files if len(o.split('_')[-1]) < 6])\n",
        "    ids = np.unique([int(o.split('_')[-1]) \n",
        "                     for o in files if len(o.split('_')[-1]) < 6])\n",
        "    file_groups = [[path_save/f'{r}_{i}{suffix}' for i in ids \n",
        "                if f'{r}_{i}' in files] for r in ref] \n",
        "    for fs in file_groups:\n",
        "        if len(fs) < 500:\n",
        "            fsave = '_'.join(fs[0].stem.split('_')[:-1]) + suffix\n",
        "            merge_tifs(fs, fsave, delete=True)\n",
        "        else:\n",
        "            fs_break = np.array(fs)[:(len(fs)//500)*500].reshape(len(fs)//500,-1).tolist()\n",
        "            if len(fs[(len(fs)//500)*500:]) > 0:\n",
        "                fs_break.append(fs[(len(fs)//500)*500:])\n",
        "            for fsi, fs2 in enumerate(fs_break):\n",
        "                fsave = '_'.join(fs2[0].stem.split('_')[:-1]) + f'_break{fsi}' + suffix\n",
        "                merge_tifs(fs2, fsave, delete=True)\n",
        "\n",
        "    files = path_save.ls(include=[suffix, '_break'])\n",
        "    files = [o.stem for o in files]\n",
        "    ref = np.unique(['_'.join(o.split('_')[:-1]) \n",
        "                     for o in files if len(o.split('_')[-1]) < 11])\n",
        "    ids = np.unique([o.split('_')[-1]\n",
        "                     for o in files if len(o.split('_')[-1]) < 11])\n",
        "    file_groups = [[path_save/f'{r}_{i}{suffix}' for i in ids \n",
        "                if f'{r}_{i}' in files] for r in ref] \n",
        "    for fs in file_groups:\n",
        "        fsave = '_'.join(fs[0].stem.split('_')[:-1]) + suffix\n",
        "        merge_tifs(fs, fsave, delete=True)"
      ],
      "metadata": {
        "id": "cgDoL5qty-Mg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**fun**"
      ],
      "metadata": {
        "id": "gsZow793zR3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Bounding box coordinates\n",
        "left   = 75.979728\n",
        "right  = 77.866667\n",
        "bottom = 31.453599\n",
        "top    = 32.416667\n",
        "\n",
        "path_save   = Path('data')\n",
        "products    = [\"JAXA/ALOS/PALSAR-2/Level2_2/ScanSAR\"]  # Product id in google earth engine\n",
        "bands       = ['HH', 'HV'] # Red, Green, Blue\n",
        "\n",
        "R = RegionST(name         = 'TeslaGigaBerlin', \n",
        "             bbox         = [left,bottom,right,top], \n",
        "             scale_meters = 10, \n",
        "             time_start   = '2020-03-01', \n",
        "             time_end     = '2020-04-25')\n",
        "\n",
        "# Download time series\n",
        "# download_data_ts(R, products, bands, path_save)\n",
        "\n",
        "time_window = R.times[0], R.times[-1]\n",
        "\n",
        "# Download median composite of the 3 least cloudy images within the time_window\n",
        "#download_data(R, time_window, products, bands, path_save, use_least_cloudy=3, show_progress=True)\n",
        "\n",
        "download_data_ts(R, products, bands, path_save, show_progress=True)"
      ],
      "metadata": {
        "id": "3-giNuSezZxi",
        "outputId": "8c3ed466-1c69-44ec-c0dd-bf742e4d84cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='56' class='' max='231' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      24.24% [56/231 14:47&lt;46:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}